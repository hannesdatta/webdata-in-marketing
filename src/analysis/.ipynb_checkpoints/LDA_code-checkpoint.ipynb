{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA topic analysis\n",
    "\n",
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, nltk, spacy, gensim\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pprint import pprint\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'../../gen/analysis/temp/coding.csv')\n",
    "df = df.dropna(subset=['abstract_wos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>paper</th>\n",
       "      <th>tc</th>\n",
       "      <th>tcperyear</th>\n",
       "      <th>ntc</th>\n",
       "      <th>year</th>\n",
       "      <th>journal</th>\n",
       "      <th>keywords</th>\n",
       "      <th>abstract_wos</th>\n",
       "      <th>nauthors</th>\n",
       "      <th>...</th>\n",
       "      <th>author_other (e.g., teaching)</th>\n",
       "      <th>sum authors</th>\n",
       "      <th>verified</th>\n",
       "      <th>adone</th>\n",
       "      <th>special issue</th>\n",
       "      <th>marked_for_review</th>\n",
       "      <th>added date</th>\n",
       "      <th>check_hd</th>\n",
       "      <th>web</th>\n",
       "      <th>is_aggregator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ESCALAS JE, 2004, J CONSUM PSYCHOL-a</td>\n",
       "      <td>537</td>\n",
       "      <td>28.263158</td>\n",
       "      <td>2.986110</td>\n",
       "      <td>2004</td>\n",
       "      <td>JCP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IN THIS RESEARCH, WE INVESTIGATE CONSUMERS' MO...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>HOMBURG C, 2005, J MARK</td>\n",
       "      <td>433</td>\n",
       "      <td>24.055556</td>\n",
       "      <td>2.899793</td>\n",
       "      <td>2004</td>\n",
       "      <td>JCP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IN THIS RESEARCH, WE INVESTIGATE CONSUMERS' MO...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>READ S, 2009, J MARK</td>\n",
       "      <td>250</td>\n",
       "      <td>17.857143</td>\n",
       "      <td>2.734648</td>\n",
       "      <td>2004</td>\n",
       "      <td>JCP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IN THIS RESEARCH, WE INVESTIGATE CONSUMERS' MO...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>HUMPHREYS A, 2010, J MARK</td>\n",
       "      <td>234</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>2.248611</td>\n",
       "      <td>2004</td>\n",
       "      <td>JCP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IN THIS RESEARCH, WE INVESTIGATE CONSUMERS' MO...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>PHAM MT, 2004, J CONSUM PSYCHOL</td>\n",
       "      <td>195</td>\n",
       "      <td>10.263158</td>\n",
       "      <td>1.084342</td>\n",
       "      <td>2004</td>\n",
       "      <td>JCP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IN THIS RESEARCH, WE INVESTIGATE CONSUMERS' MO...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   doi                        paper            tc  tcperyear       ntc  year  \\\n",
       "0  NaN  ESCALAS JE, 2004, J CONSUM PSYCHOL-a  537  28.263158  2.986110  2004   \n",
       "1  NaN               HOMBURG C, 2005, J MARK  433  24.055556  2.899793  2004   \n",
       "2  NaN                  READ S, 2009, J MARK  250  17.857143  2.734648  2004   \n",
       "3  NaN             HUMPHREYS A, 2010, J MARK  234  18.000000  2.248611  2004   \n",
       "4  NaN       PHAM MT, 2004, J CONSUM PSYCHOL  195  10.263158  1.084342  2004   \n",
       "\n",
       "  journal keywords                                       abstract_wos  \\\n",
       "0     JCP      NaN  IN THIS RESEARCH, WE INVESTIGATE CONSUMERS' MO...   \n",
       "1     JCP      NaN  IN THIS RESEARCH, WE INVESTIGATE CONSUMERS' MO...   \n",
       "2     JCP      NaN  IN THIS RESEARCH, WE INVESTIGATE CONSUMERS' MO...   \n",
       "3     JCP      NaN  IN THIS RESEARCH, WE INVESTIGATE CONSUMERS' MO...   \n",
       "4     JCP      NaN  IN THIS RESEARCH, WE INVESTIGATE CONSUMERS' MO...   \n",
       "\n",
       "   nauthors  ...  author_other (e.g., teaching) sum authors  verified adone  \\\n",
       "0       NaN  ...                            NaN         NaN       NaN   NaN   \n",
       "1       NaN  ...                            NaN         NaN       NaN   NaN   \n",
       "2       NaN  ...                            NaN         NaN       NaN   NaN   \n",
       "3       NaN  ...                            NaN         NaN       NaN   NaN   \n",
       "4       NaN  ...                            NaN         NaN       NaN   NaN   \n",
       "\n",
       "   special issue  marked_for_review  added date  check_hd    web is_aggregator  \n",
       "0            NaN                NaN         NaN       NaN  False           NaN  \n",
       "1            NaN                NaN         NaN       NaN  False           NaN  \n",
       "2            NaN                NaN         NaN       NaN  False           NaN  \n",
       "3            NaN                NaN         NaN       NaN  False           NaN  \n",
       "4            NaN                NaN         NaN       NaN  False           NaN  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4707, 62)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to list\n",
    "\n",
    "data = df.abstract_wos.values.tolist()\n",
    "# Remove Emails\n",
    "data = [re.sub(r'\\S*@\\S*\\s?', '', sent) for sent in data]\n",
    "# Remove new line characters\n",
    "data = [re.sub(r'\\s+', ' ', sent) for sent in data]\n",
    "# Remove distracting single quotes\n",
    "data = [re.sub(r\"\\'\", \"\", sent) for sent in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4707"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "data_words = list(sent_to_words(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4707"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "avoid_these_words=['article','articles','author','authors','study','studied','studies','studying']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all=[]\n",
    "for x in data_words:\n",
    "    sub=[]\n",
    "    for y in x:\n",
    "        if y not in avoid_these_words:\n",
    "            sub.append(y)\n",
    "    all.append(sub)        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']): #'NOUN', 'ADJ', 'VERB', 'ADV'\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append(\" \".join([token.lemma_ if token.lemma_ not in ['-PRON-'] else '' for token in doc if token.pos_ in allowed_postags]))\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize spacy ‘en’ model, keeping only tagger component (for efficiency)\n",
    "# Run in terminal: python -m spacy download en\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "# Do lemmatization keeping only Noun, Adj, Verb, Adverb\n",
    "data_lemmatized = lemmatization(all, allowed_postags=['NOUN', 'VERB']) #select noun and verb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document-Word matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word',       \n",
    "                             min_df=10, # minimum reqd occurences of a word \n",
    "                             stop_words='english', # remove stop words\n",
    "                             lowercase=True,# convert all words to lowercase\n",
    "                             token_pattern='[a-zA-Z0-9]{3,}',  \n",
    "                             # num chars > 3\n",
    "                             # max_features=50000, \n",
    "                             # max number of uniq words    \n",
    "                            )\n",
    "data_vectorized = vectorizer.fit_transform(data_lemmatized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build LDA model\n",
    "\n",
    "with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LatentDirichletAllocation(learning_method='online', n_components=6, n_jobs=-1,\n",
      "                          random_state=100)\n"
     ]
    }
   ],
   "source": [
    "# Build LDA Model\n",
    "lda_model = LatentDirichletAllocation(n_components=6,               # Number of topics\n",
    "                                      max_iter=10,               \n",
    "# Max learning iterations\n",
    "                                      learning_method='online',   \n",
    "                                      random_state=100,          \n",
    "# Random state\n",
    "                                      batch_size=128,            \n",
    "# n docs in each learning iter\n",
    "                                      evaluate_every = -1,       \n",
    "# compute perplexity every n iters, default: Don't\n",
    "                                      n_jobs = -1,               \n",
    "# Use all available CPUs\n",
    "                                     )\n",
    "lda_output = lda_model.fit_transform(data_vectorized)\n",
    "print(lda_model)  # Model attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnising model performance with perplexity and log-likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Likelihood:  -2001696.8245067187\n",
      "Perplexity:  678.0125600111246\n",
      "{'batch_size': 128,\n",
      " 'doc_topic_prior': None,\n",
      " 'evaluate_every': -1,\n",
      " 'learning_decay': 0.7,\n",
      " 'learning_method': 'online',\n",
      " 'learning_offset': 10.0,\n",
      " 'max_doc_update_iter': 100,\n",
      " 'max_iter': 10,\n",
      " 'mean_change_tol': 0.001,\n",
      " 'n_components': 6,\n",
      " 'n_jobs': -1,\n",
      " 'perp_tol': 0.1,\n",
      " 'random_state': 100,\n",
      " 'topic_word_prior': None,\n",
      " 'total_samples': 1000000.0,\n",
      " 'verbose': 0}\n"
     ]
    }
   ],
   "source": [
    "# Log Likelyhood: Higher the better\n",
    "print(\"Log Likelihood: \", lda_model.score(data_vectorized))\n",
    "# Perplexity: Lower the better. Perplexity = exp(-1. * log-likelihood per word)\n",
    "print(\"Perplexity: \", lda_model.perplexity(data_vectorized))\n",
    "# See model parameters\n",
    "pprint(lda_model.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using GridSearch\n",
    "to determine the best LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hannesdatta/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:443: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  fold_sizes = np.full(n_splits, n_samples // n_splits, dtype=np.int)\n",
      "/Users/hannesdatta/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:93: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
      "/Users/hannesdatta/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:93: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
      "/Users/hannesdatta/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:93: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
      "/Users/hannesdatta/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:93: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n",
      "/Users/hannesdatta/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:93: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_mask = np.zeros(_num_samples(X), dtype=np.bool)\n"
     ]
    }
   ],
   "source": [
    "# Define Search Param\n",
    "search_params = {'n_components': [4,5,6,7,8,9,10,11,12], 'learning_decay': [.3,.4,.5,.6,.7,.8,.9]}\n",
    "# Init the Model\n",
    "lda = LatentDirichletAllocation(max_iter=5, learning_method='online', learning_offset=50.,random_state=0)\n",
    "# Init Grid Search Class\n",
    "model = GridSearchCV(lda, param_grid=search_params)\n",
    "# Do the Grid Search\n",
    "model.fit(data_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhi\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model's Params:  {'learning_decay': 0.6, 'n_components': 4}\n",
      "Best Log Likelihood Score:  -415581.8654101815\n",
      "Model Perplexity:  677.2712870514948\n"
     ]
    }
   ],
   "source": [
    "# Best Model\n",
    "best_lda_model = model.best_estimator_\n",
    "# Model Parameters\n",
    "print(\"Best Model's Params: \", model.best_params_)\n",
    "# Log Likelihood Score\n",
    "print(\"Best Log Likelihood Score: \", model.best_score_)\n",
    "# Perplexity\n",
    "print(\"Model Perplexity: \", best_lda_model.perplexity(data_vectorized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract dominant topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhi\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_7444f_row0_col0,#T_7444f_row0_col2,#T_7444f_row0_col3,#T_7444f_row1_col1,#T_7444f_row1_col2,#T_7444f_row1_col3,#T_7444f_row1_col4,#T_7444f_row2_col2,#T_7444f_row2_col3,#T_7444f_row3_col1,#T_7444f_row3_col2,#T_7444f_row3_col3,#T_7444f_row3_col4,#T_7444f_row4_col3,#T_7444f_row5_col1,#T_7444f_row5_col2,#T_7444f_row5_col4,#T_7444f_row6_col2,#T_7444f_row6_col3,#T_7444f_row7_col2,#T_7444f_row7_col3,#T_7444f_row8_col2,#T_7444f_row8_col3,#T_7444f_row9_col3,#T_7444f_row9_col4,#T_7444f_row10_col0,#T_7444f_row10_col3,#T_7444f_row11_col0,#T_7444f_row11_col3,#T_7444f_row12_col2,#T_7444f_row12_col3,#T_7444f_row13_col0,#T_7444f_row14_col2,#T_7444f_row14_col3{\n",
       "            color:  black;\n",
       "            font-weight:  400;\n",
       "        }#T_7444f_row0_col1,#T_7444f_row0_col4,#T_7444f_row1_col0,#T_7444f_row2_col0,#T_7444f_row2_col1,#T_7444f_row2_col4,#T_7444f_row3_col0,#T_7444f_row4_col0,#T_7444f_row4_col1,#T_7444f_row4_col2,#T_7444f_row4_col4,#T_7444f_row5_col0,#T_7444f_row5_col3,#T_7444f_row6_col0,#T_7444f_row6_col1,#T_7444f_row6_col4,#T_7444f_row7_col0,#T_7444f_row7_col1,#T_7444f_row7_col4,#T_7444f_row8_col0,#T_7444f_row8_col1,#T_7444f_row8_col4,#T_7444f_row9_col0,#T_7444f_row9_col1,#T_7444f_row9_col2,#T_7444f_row10_col1,#T_7444f_row10_col2,#T_7444f_row10_col4,#T_7444f_row11_col1,#T_7444f_row11_col2,#T_7444f_row11_col4,#T_7444f_row12_col0,#T_7444f_row12_col1,#T_7444f_row12_col4,#T_7444f_row13_col1,#T_7444f_row13_col2,#T_7444f_row13_col3,#T_7444f_row13_col4,#T_7444f_row14_col0,#T_7444f_row14_col1,#T_7444f_row14_col4{\n",
       "            color:  green;\n",
       "            font-weight:  700;\n",
       "        }</style><table id=\"T_7444f_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Topic0</th>        <th class=\"col_heading level0 col1\" >Topic1</th>        <th class=\"col_heading level0 col2\" >Topic2</th>        <th class=\"col_heading level0 col3\" >Topic3</th>        <th class=\"col_heading level0 col4\" >dominant_topic</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_7444f_level0_row0\" class=\"row_heading level0 row0\" >Doc0</th>\n",
       "                        <td id=\"T_7444f_row0_col0\" class=\"data row0 col0\" >0.010000</td>\n",
       "                        <td id=\"T_7444f_row0_col1\" class=\"data row0 col1\" >0.900000</td>\n",
       "                        <td id=\"T_7444f_row0_col2\" class=\"data row0 col2\" >0.090000</td>\n",
       "                        <td id=\"T_7444f_row0_col3\" class=\"data row0 col3\" >0.010000</td>\n",
       "                        <td id=\"T_7444f_row0_col4\" class=\"data row0 col4\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7444f_level0_row1\" class=\"row_heading level0 row1\" >Doc1</th>\n",
       "                        <td id=\"T_7444f_row1_col0\" class=\"data row1 col0\" >0.980000</td>\n",
       "                        <td id=\"T_7444f_row1_col1\" class=\"data row1 col1\" >0.010000</td>\n",
       "                        <td id=\"T_7444f_row1_col2\" class=\"data row1 col2\" >0.010000</td>\n",
       "                        <td id=\"T_7444f_row1_col3\" class=\"data row1 col3\" >0.010000</td>\n",
       "                        <td id=\"T_7444f_row1_col4\" class=\"data row1 col4\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7444f_level0_row2\" class=\"row_heading level0 row2\" >Doc2</th>\n",
       "                        <td id=\"T_7444f_row2_col0\" class=\"data row2 col0\" >0.130000</td>\n",
       "                        <td id=\"T_7444f_row2_col1\" class=\"data row2 col1\" >0.850000</td>\n",
       "                        <td id=\"T_7444f_row2_col2\" class=\"data row2 col2\" >0.010000</td>\n",
       "                        <td id=\"T_7444f_row2_col3\" class=\"data row2 col3\" >0.010000</td>\n",
       "                        <td id=\"T_7444f_row2_col4\" class=\"data row2 col4\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7444f_level0_row3\" class=\"row_heading level0 row3\" >Doc3</th>\n",
       "                        <td id=\"T_7444f_row3_col0\" class=\"data row3 col0\" >0.920000</td>\n",
       "                        <td id=\"T_7444f_row3_col1\" class=\"data row3 col1\" >0.070000</td>\n",
       "                        <td id=\"T_7444f_row3_col2\" class=\"data row3 col2\" >0.010000</td>\n",
       "                        <td id=\"T_7444f_row3_col3\" class=\"data row3 col3\" >0.010000</td>\n",
       "                        <td id=\"T_7444f_row3_col4\" class=\"data row3 col4\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7444f_level0_row4\" class=\"row_heading level0 row4\" >Doc4</th>\n",
       "                        <td id=\"T_7444f_row4_col0\" class=\"data row4 col0\" >0.110000</td>\n",
       "                        <td id=\"T_7444f_row4_col1\" class=\"data row4 col1\" >0.640000</td>\n",
       "                        <td id=\"T_7444f_row4_col2\" class=\"data row4 col2\" >0.250000</td>\n",
       "                        <td id=\"T_7444f_row4_col3\" class=\"data row4 col3\" >0.010000</td>\n",
       "                        <td id=\"T_7444f_row4_col4\" class=\"data row4 col4\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7444f_level0_row5\" class=\"row_heading level0 row5\" >Doc5</th>\n",
       "                        <td id=\"T_7444f_row5_col0\" class=\"data row5 col0\" >0.740000</td>\n",
       "                        <td id=\"T_7444f_row5_col1\" class=\"data row5 col1\" >0.090000</td>\n",
       "                        <td id=\"T_7444f_row5_col2\" class=\"data row5 col2\" >0.010000</td>\n",
       "                        <td id=\"T_7444f_row5_col3\" class=\"data row5 col3\" >0.170000</td>\n",
       "                        <td id=\"T_7444f_row5_col4\" class=\"data row5 col4\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7444f_level0_row6\" class=\"row_heading level0 row6\" >Doc6</th>\n",
       "                        <td id=\"T_7444f_row6_col0\" class=\"data row6 col0\" >0.470000</td>\n",
       "                        <td id=\"T_7444f_row6_col1\" class=\"data row6 col1\" >0.530000</td>\n",
       "                        <td id=\"T_7444f_row6_col2\" class=\"data row6 col2\" >0.000000</td>\n",
       "                        <td id=\"T_7444f_row6_col3\" class=\"data row6 col3\" >0.000000</td>\n",
       "                        <td id=\"T_7444f_row6_col4\" class=\"data row6 col4\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7444f_level0_row7\" class=\"row_heading level0 row7\" >Doc7</th>\n",
       "                        <td id=\"T_7444f_row7_col0\" class=\"data row7 col0\" >0.300000</td>\n",
       "                        <td id=\"T_7444f_row7_col1\" class=\"data row7 col1\" >0.690000</td>\n",
       "                        <td id=\"T_7444f_row7_col2\" class=\"data row7 col2\" >0.010000</td>\n",
       "                        <td id=\"T_7444f_row7_col3\" class=\"data row7 col3\" >0.010000</td>\n",
       "                        <td id=\"T_7444f_row7_col4\" class=\"data row7 col4\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7444f_level0_row8\" class=\"row_heading level0 row8\" >Doc8</th>\n",
       "                        <td id=\"T_7444f_row8_col0\" class=\"data row8 col0\" >0.270000</td>\n",
       "                        <td id=\"T_7444f_row8_col1\" class=\"data row8 col1\" >0.720000</td>\n",
       "                        <td id=\"T_7444f_row8_col2\" class=\"data row8 col2\" >0.000000</td>\n",
       "                        <td id=\"T_7444f_row8_col3\" class=\"data row8 col3\" >0.000000</td>\n",
       "                        <td id=\"T_7444f_row8_col4\" class=\"data row8 col4\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7444f_level0_row9\" class=\"row_heading level0 row9\" >Doc9</th>\n",
       "                        <td id=\"T_7444f_row9_col0\" class=\"data row9 col0\" >0.480000</td>\n",
       "                        <td id=\"T_7444f_row9_col1\" class=\"data row9 col1\" >0.390000</td>\n",
       "                        <td id=\"T_7444f_row9_col2\" class=\"data row9 col2\" >0.120000</td>\n",
       "                        <td id=\"T_7444f_row9_col3\" class=\"data row9 col3\" >0.010000</td>\n",
       "                        <td id=\"T_7444f_row9_col4\" class=\"data row9 col4\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7444f_level0_row10\" class=\"row_heading level0 row10\" >Doc10</th>\n",
       "                        <td id=\"T_7444f_row10_col0\" class=\"data row10 col0\" >0.000000</td>\n",
       "                        <td id=\"T_7444f_row10_col1\" class=\"data row10 col1\" >0.420000</td>\n",
       "                        <td id=\"T_7444f_row10_col2\" class=\"data row10 col2\" >0.570000</td>\n",
       "                        <td id=\"T_7444f_row10_col3\" class=\"data row10 col3\" >0.000000</td>\n",
       "                        <td id=\"T_7444f_row10_col4\" class=\"data row10 col4\" >2</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7444f_level0_row11\" class=\"row_heading level0 row11\" >Doc11</th>\n",
       "                        <td id=\"T_7444f_row11_col0\" class=\"data row11 col0\" >0.010000</td>\n",
       "                        <td id=\"T_7444f_row11_col1\" class=\"data row11 col1\" >0.270000</td>\n",
       "                        <td id=\"T_7444f_row11_col2\" class=\"data row11 col2\" >0.710000</td>\n",
       "                        <td id=\"T_7444f_row11_col3\" class=\"data row11 col3\" >0.010000</td>\n",
       "                        <td id=\"T_7444f_row11_col4\" class=\"data row11 col4\" >2</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7444f_level0_row12\" class=\"row_heading level0 row12\" >Doc12</th>\n",
       "                        <td id=\"T_7444f_row12_col0\" class=\"data row12 col0\" >0.300000</td>\n",
       "                        <td id=\"T_7444f_row12_col1\" class=\"data row12 col1\" >0.700000</td>\n",
       "                        <td id=\"T_7444f_row12_col2\" class=\"data row12 col2\" >0.000000</td>\n",
       "                        <td id=\"T_7444f_row12_col3\" class=\"data row12 col3\" >0.000000</td>\n",
       "                        <td id=\"T_7444f_row12_col4\" class=\"data row12 col4\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7444f_level0_row13\" class=\"row_heading level0 row13\" >Doc13</th>\n",
       "                        <td id=\"T_7444f_row13_col0\" class=\"data row13 col0\" >0.010000</td>\n",
       "                        <td id=\"T_7444f_row13_col1\" class=\"data row13 col1\" >0.440000</td>\n",
       "                        <td id=\"T_7444f_row13_col2\" class=\"data row13 col2\" >0.390000</td>\n",
       "                        <td id=\"T_7444f_row13_col3\" class=\"data row13 col3\" >0.160000</td>\n",
       "                        <td id=\"T_7444f_row13_col4\" class=\"data row13 col4\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_7444f_level0_row14\" class=\"row_heading level0 row14\" >Doc14</th>\n",
       "                        <td id=\"T_7444f_row14_col0\" class=\"data row14 col0\" >0.280000</td>\n",
       "                        <td id=\"T_7444f_row14_col1\" class=\"data row14 col1\" >0.710000</td>\n",
       "                        <td id=\"T_7444f_row14_col2\" class=\"data row14 col2\" >0.010000</td>\n",
       "                        <td id=\"T_7444f_row14_col3\" class=\"data row14 col3\" >0.010000</td>\n",
       "                        <td id=\"T_7444f_row14_col4\" class=\"data row14 col4\" >1</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x19a17318640>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Document — Topic Matrix\n",
    "lda_output = best_lda_model.transform(data_vectorized)\n",
    "# column names\n",
    "topicnames = [\"Topic\" + str(i) for i in range(best_lda_model.n_components)]\n",
    "# index names\n",
    "docnames = [\"Doc\" + str(i) for i in range(len(data))]\n",
    "# Make the pandas dataframe\n",
    "df_document_topic = pd.DataFrame(np.round(lda_output, 2), columns=topicnames, index=docnames)\n",
    "# Get dominant topic for each document\n",
    "dominant_topic = np.argmax(df_document_topic.values, axis=1)\n",
    "df_document_topic['dominant_topic'] = dominant_topic\n",
    "\n",
    "# Styling\n",
    "def color_green(val):\n",
    " color = 'green' if val > .1 else 'black'\n",
    " return 'color: {col}'.format(col=color)\n",
    "def make_bold(val):\n",
    " weight = 700 if val > .1 else 400\n",
    " return 'font-weight: {weight}'.format(weight=weight)\n",
    "\n",
    "# Apply Style\n",
    "df_document_topics = df_document_topic.head(15).style.applymap(color_green).applymap(make_bold)\n",
    "df_document_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhi\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic0</th>\n",
       "      <th>Topic1</th>\n",
       "      <th>Topic2</th>\n",
       "      <th>Topic3</th>\n",
       "      <th>dominant_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc1</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc3</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc4</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Topic0  Topic1  Topic2  Topic3  dominant_topic\n",
       "Doc0    0.01    0.90    0.09    0.01               1\n",
       "Doc1    0.98    0.01    0.01    0.01               0\n",
       "Doc2    0.13    0.85    0.01    0.01               1\n",
       "Doc3    0.92    0.07    0.01    0.01               0\n",
       "Doc4    0.11    0.64    0.25    0.01               1"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_document_topic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhi\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "df_document_topic.to_csv(\"../../gen/analysis/temp/lda_analysis.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhi\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "#top_30_keywords_for_each_topic!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhi\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 0</th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Word 3</th>\n",
       "      <th>Word 4</th>\n",
       "      <th>Word 5</th>\n",
       "      <th>Word 6</th>\n",
       "      <th>Word 7</th>\n",
       "      <th>Word 8</th>\n",
       "      <th>Word 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Word 20</th>\n",
       "      <th>Word 21</th>\n",
       "      <th>Word 22</th>\n",
       "      <th>Word 23</th>\n",
       "      <th>Word 24</th>\n",
       "      <th>Word 25</th>\n",
       "      <th>Word 26</th>\n",
       "      <th>Word 27</th>\n",
       "      <th>Word 28</th>\n",
       "      <th>Word 29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic 0</th>\n",
       "      <td>product</td>\n",
       "      <td>consumer</td>\n",
       "      <td>effect</td>\n",
       "      <td>choice</td>\n",
       "      <td>preference</td>\n",
       "      <td>decision</td>\n",
       "      <td>information</td>\n",
       "      <td>experiment</td>\n",
       "      <td>research</td>\n",
       "      <td>influence</td>\n",
       "      <td>...</td>\n",
       "      <td>purchase</td>\n",
       "      <td>brand</td>\n",
       "      <td>finding</td>\n",
       "      <td>experience</td>\n",
       "      <td>base</td>\n",
       "      <td>people</td>\n",
       "      <td>lead</td>\n",
       "      <td>level</td>\n",
       "      <td>perceive</td>\n",
       "      <td>propose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 1</th>\n",
       "      <td>consumer</td>\n",
       "      <td>self</td>\n",
       "      <td>research</td>\n",
       "      <td>consumption</td>\n",
       "      <td>behavior</td>\n",
       "      <td>brand</td>\n",
       "      <td>effect</td>\n",
       "      <td>experience</td>\n",
       "      <td>goal</td>\n",
       "      <td>people</td>\n",
       "      <td>...</td>\n",
       "      <td>result</td>\n",
       "      <td>role</td>\n",
       "      <td>theory</td>\n",
       "      <td>time</td>\n",
       "      <td>perceive</td>\n",
       "      <td>suggest</td>\n",
       "      <td>provide</td>\n",
       "      <td>emotion</td>\n",
       "      <td>status</td>\n",
       "      <td>group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 2</th>\n",
       "      <td>customer</td>\n",
       "      <td>model</td>\n",
       "      <td>firm</td>\n",
       "      <td>brand</td>\n",
       "      <td>use</td>\n",
       "      <td>marketing</td>\n",
       "      <td>market</td>\n",
       "      <td>datum</td>\n",
       "      <td>effect</td>\n",
       "      <td>advertising</td>\n",
       "      <td>...</td>\n",
       "      <td>develop</td>\n",
       "      <td>provide</td>\n",
       "      <td>impact</td>\n",
       "      <td>research</td>\n",
       "      <td>approach</td>\n",
       "      <td>manager</td>\n",
       "      <td>increase</td>\n",
       "      <td>estimate</td>\n",
       "      <td>network</td>\n",
       "      <td>method</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 3</th>\n",
       "      <td>price</td>\n",
       "      <td>consumer</td>\n",
       "      <td>retailer</td>\n",
       "      <td>cost</td>\n",
       "      <td>increase</td>\n",
       "      <td>store</td>\n",
       "      <td>purchase</td>\n",
       "      <td>pricing</td>\n",
       "      <td>effect</td>\n",
       "      <td>search</td>\n",
       "      <td>...</td>\n",
       "      <td>pay</td>\n",
       "      <td>quality</td>\n",
       "      <td>seller</td>\n",
       "      <td>policy</td>\n",
       "      <td>food</td>\n",
       "      <td>time</td>\n",
       "      <td>competition</td>\n",
       "      <td>decrease</td>\n",
       "      <td>incentive</td>\n",
       "      <td>sale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word 0    Word 1    Word 2       Word 3      Word 4     Word 5  \\\n",
       "Topic 0   product  consumer    effect       choice  preference   decision   \n",
       "Topic 1  consumer      self  research  consumption    behavior      brand   \n",
       "Topic 2  customer     model      firm        brand         use  marketing   \n",
       "Topic 3     price  consumer  retailer         cost    increase      store   \n",
       "\n",
       "              Word 6      Word 7    Word 8       Word 9  ...   Word 20  \\\n",
       "Topic 0  information  experiment  research    influence  ...  purchase   \n",
       "Topic 1       effect  experience      goal       people  ...    result   \n",
       "Topic 2       market       datum    effect  advertising  ...   develop   \n",
       "Topic 3     purchase     pricing    effect       search  ...       pay   \n",
       "\n",
       "         Word 21  Word 22     Word 23   Word 24  Word 25      Word 26  \\\n",
       "Topic 0    brand  finding  experience      base   people         lead   \n",
       "Topic 1     role   theory        time  perceive  suggest      provide   \n",
       "Topic 2  provide   impact    research  approach  manager     increase   \n",
       "Topic 3  quality   seller      policy      food     time  competition   \n",
       "\n",
       "          Word 27    Word 28  Word 29  \n",
       "Topic 0     level   perceive  propose  \n",
       "Topic 1   emotion     status    group  \n",
       "Topic 2  estimate    network   method  \n",
       "Topic 3  decrease  incentive     sale  \n",
       "\n",
       "[4 rows x 30 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show top n keywords for each topic\n",
    "def show_topics(vectorizer=vectorizer, lda_model=lda_model, n_words=30):\n",
    "    keywords = np.array(vectorizer.get_feature_names())\n",
    "    topic_keywords = []\n",
    "    for topic_weights in lda_model.components_:\n",
    "        top_keyword_locs = (-topic_weights).argsort()[:n_words]\n",
    "        topic_keywords.append(keywords.take(top_keyword_locs))\n",
    "    return topic_keywords\n",
    "topic_keywords = show_topics(vectorizer=vectorizer, lda_model=best_lda_model, n_words=30)\n",
    "# Topic - Keywords Dataframe\n",
    "df_topic_keywords = pd.DataFrame(topic_keywords)\n",
    "df_topic_keywords.columns = ['Word '+str(i) for i in range(df_topic_keywords.shape[1])]\n",
    "df_topic_keywords.index = ['Topic '+str(i) for i in range(df_topic_keywords.shape[0])]\n",
    "df_topic_keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhi\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "df_topic_keywords=df_topic_keywords.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhi\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 0</th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "      <th>Topic 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Word 0</th>\n",
       "      <td>product</td>\n",
       "      <td>consumer</td>\n",
       "      <td>customer</td>\n",
       "      <td>price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word 1</th>\n",
       "      <td>consumer</td>\n",
       "      <td>self</td>\n",
       "      <td>model</td>\n",
       "      <td>consumer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word 2</th>\n",
       "      <td>effect</td>\n",
       "      <td>research</td>\n",
       "      <td>firm</td>\n",
       "      <td>retailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word 3</th>\n",
       "      <td>choice</td>\n",
       "      <td>consumption</td>\n",
       "      <td>brand</td>\n",
       "      <td>cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word 4</th>\n",
       "      <td>preference</td>\n",
       "      <td>behavior</td>\n",
       "      <td>use</td>\n",
       "      <td>increase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word 5</th>\n",
       "      <td>decision</td>\n",
       "      <td>brand</td>\n",
       "      <td>marketing</td>\n",
       "      <td>store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word 6</th>\n",
       "      <td>information</td>\n",
       "      <td>effect</td>\n",
       "      <td>market</td>\n",
       "      <td>purchase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word 7</th>\n",
       "      <td>experiment</td>\n",
       "      <td>experience</td>\n",
       "      <td>datum</td>\n",
       "      <td>pricing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word 8</th>\n",
       "      <td>research</td>\n",
       "      <td>goal</td>\n",
       "      <td>effect</td>\n",
       "      <td>effect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word 9</th>\n",
       "      <td>influence</td>\n",
       "      <td>people</td>\n",
       "      <td>advertising</td>\n",
       "      <td>search</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word 10</th>\n",
       "      <td>attribute</td>\n",
       "      <td>identity</td>\n",
       "      <td>sale</td>\n",
       "      <td>demand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word 11</th>\n",
       "      <td>make</td>\n",
       "      <td>examine</td>\n",
       "      <td>product</td>\n",
       "      <td>category</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word 12</th>\n",
       "      <td>result</td>\n",
       "      <td>relationship</td>\n",
       "      <td>value</td>\n",
       "      <td>promotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word 13</th>\n",
       "      <td>demonstrate</td>\n",
       "      <td>finding</td>\n",
       "      <td>result</td>\n",
       "      <td>use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word 14</th>\n",
       "      <td>use</td>\n",
       "      <td>control</td>\n",
       "      <td>performance</td>\n",
       "      <td>product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word 15</th>\n",
       "      <td>process</td>\n",
       "      <td>demonstrate</td>\n",
       "      <td>relationship</td>\n",
       "      <td>profit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word 16</th>\n",
       "      <td>evaluation</td>\n",
       "      <td>increase</td>\n",
       "      <td>level</td>\n",
       "      <td>manufacturer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word 17</th>\n",
       "      <td>increase</td>\n",
       "      <td>implication</td>\n",
       "      <td>base</td>\n",
       "      <td>result</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word 18</th>\n",
       "      <td>affect</td>\n",
       "      <td>influence</td>\n",
       "      <td>service</td>\n",
       "      <td>offer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word 19</th>\n",
       "      <td>option</td>\n",
       "      <td>use</td>\n",
       "      <td>analysis</td>\n",
       "      <td>discount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word 20</th>\n",
       "      <td>purchase</td>\n",
       "      <td>result</td>\n",
       "      <td>develop</td>\n",
       "      <td>pay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word 21</th>\n",
       "      <td>brand</td>\n",
       "      <td>role</td>\n",
       "      <td>provide</td>\n",
       "      <td>quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word 22</th>\n",
       "      <td>finding</td>\n",
       "      <td>theory</td>\n",
       "      <td>impact</td>\n",
       "      <td>seller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word 23</th>\n",
       "      <td>experience</td>\n",
       "      <td>time</td>\n",
       "      <td>research</td>\n",
       "      <td>policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word 24</th>\n",
       "      <td>base</td>\n",
       "      <td>perceive</td>\n",
       "      <td>approach</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word 25</th>\n",
       "      <td>people</td>\n",
       "      <td>suggest</td>\n",
       "      <td>manager</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word 26</th>\n",
       "      <td>lead</td>\n",
       "      <td>provide</td>\n",
       "      <td>increase</td>\n",
       "      <td>competition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word 27</th>\n",
       "      <td>level</td>\n",
       "      <td>emotion</td>\n",
       "      <td>estimate</td>\n",
       "      <td>decrease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word 28</th>\n",
       "      <td>perceive</td>\n",
       "      <td>status</td>\n",
       "      <td>network</td>\n",
       "      <td>incentive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word 29</th>\n",
       "      <td>propose</td>\n",
       "      <td>group</td>\n",
       "      <td>method</td>\n",
       "      <td>sale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Topic 0       Topic 1       Topic 2       Topic 3\n",
       "Word 0       product      consumer      customer         price\n",
       "Word 1      consumer          self         model      consumer\n",
       "Word 2        effect      research          firm      retailer\n",
       "Word 3        choice   consumption         brand          cost\n",
       "Word 4    preference      behavior           use      increase\n",
       "Word 5      decision         brand     marketing         store\n",
       "Word 6   information        effect        market      purchase\n",
       "Word 7    experiment    experience         datum       pricing\n",
       "Word 8      research          goal        effect        effect\n",
       "Word 9     influence        people   advertising        search\n",
       "Word 10    attribute      identity          sale        demand\n",
       "Word 11         make       examine       product      category\n",
       "Word 12       result  relationship         value     promotion\n",
       "Word 13  demonstrate       finding        result           use\n",
       "Word 14          use       control   performance       product\n",
       "Word 15      process   demonstrate  relationship        profit\n",
       "Word 16   evaluation      increase         level  manufacturer\n",
       "Word 17     increase   implication          base        result\n",
       "Word 18       affect     influence       service         offer\n",
       "Word 19       option           use      analysis      discount\n",
       "Word 20     purchase        result       develop           pay\n",
       "Word 21        brand          role       provide       quality\n",
       "Word 22      finding        theory        impact        seller\n",
       "Word 23   experience          time      research        policy\n",
       "Word 24         base      perceive      approach          food\n",
       "Word 25       people       suggest       manager          time\n",
       "Word 26         lead       provide      increase   competition\n",
       "Word 27        level       emotion      estimate      decrease\n",
       "Word 28     perceive        status       network     incentive\n",
       "Word 29      propose         group        method          sale"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topic_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhi\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "df_topic_keywords.to_csv('../../gen/analysis/temp/top_keywords.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
